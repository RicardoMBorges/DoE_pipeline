{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baee30be",
   "metadata": {},
   "source": [
    "## Workflow for Design of Experiment: _More General_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fd9648",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyDOE2 import *\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "from IPython.display import display, HTML\n",
    "import plotly.graph_objs as go\n",
    "import os\n",
    "\n",
    "import data_processing as dp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59d97ec",
   "metadata": {},
   "source": [
    "#### This cell will contain a function to select among different design options like Full Factorial, Fractional Factorial, etc., and create the design table.\n",
    "\n",
    "* The function _create_design_ is designed to accommodate different experimental needs by creating several types of designs like Full Factorial, Fractional Factorial, Plackett Burman, Box Behnken, Central Composite, and Latin Hypercube designs. \n",
    "\n",
    "#### Design Types:\n",
    "\n",
    "* General Full Factorial: Generates a full factorial design with a specified number of levels and factors.\n",
    "* 2 Level Full Factorial: Creates a 2-level full factorial design for a specified number of factors.\n",
    "* 2 Level Fractional Factorial: Produces a fractional factorial design based on a generator string that indicates the allowed confounding.\n",
    "* Plackett Burman: Used for generating fractional-factorial designs, especially for a large number of factors.\n",
    "* Box Behnken: Suitable for 3-level designs and includes a central point for each factor. Often used for response surface methodology.\n",
    "* Central Composite: Generates a central composite design, commonly used in response surface methodology.\n",
    "* Latin Hypercube: Creates a Latin hypercube sample design, useful for creating random samples of parameter values from a multidimensional distribution.\n",
    "\n",
    "#### Additional Notes\n",
    "\n",
    "* It's important to refer to the documentation of pyDOE2 and the NIST handbook provided in the function comments for detailed explanations of each design type.\n",
    "* _Design Selection:_ Choose the design type based on your experimental needs. For example, full factorial designs are comprehensive but may require a large number of experiments, while fractional factorial designs like Plackett Burman and Box Behnken can be more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc397b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_design(design_type, *args):\n",
    "    '''\n",
    "    Refer to:\n",
    "     # https://pythonhosted.org/pyDOE/\n",
    "     # https://www.itl.nist.gov/div898/handbook/pri/section3/pri33.htm\n",
    "     # https://github.com/clicumu/pyDOE2/tree/master\n",
    "    \n",
    "    # Mostly Used: \n",
    "     # 2 level full factorial design for 2 Level and # factors\n",
    "     # Plackett Burman for fractional-factorial designs \n",
    "     # Box Behnken for 3 level (includes a central point) for each # factors\n",
    "    \n",
    "    '''\n",
    "    if design_type == \"General Full Factorial\":\n",
    "        design = fullfact(*args)       # define the number of 3 Levels for n Factors.\n",
    "        #design_table = fullfact([3,3,3]) # for 3 levels in 3 Factors\n",
    "        \n",
    "    elif design_type == \"2 Level Full Factorial\":\n",
    "        design = ff2n(*args)       # define the number of Factors ex. 3 for Temp, Slope, pH\n",
    "        #design_table = create_design(\"2_level_full_factorial\",3)\n",
    "        \n",
    "    elif design_type == \"2 Level Fractional Factorial\":\n",
    "        design = fracfact(*args)   # the input to fracfact is a generator string of symbolic characters to indicate the 'confounding' that will be allowed\n",
    "        #design_table = create_design(\"2_level_fractional_factorial\",'a b ab')\n",
    "        \n",
    "    elif design_type == \"Plackett Burman\":\n",
    "        design = pbdesign(*args)   # Similar to  generate fractional-factorial designs, define the number of Factors \n",
    "        #design_table = create_design(\"plackett_burman\",3)\n",
    "        \n",
    "    elif design_type == \"Box Behnken\":\n",
    "        design = bbdesign(*args)   # \"These designs are rotatable (or near rotatable) and require 3 levels of each factor.\"\n",
    "        #design_table = create_design(\"box_behnken\",3)\n",
    "        \n",
    "    elif design_type == \"Central Composite\":\n",
    "        design = ccdesign(*args)\n",
    "        #design_table = ccdesign(3)\n",
    "        \n",
    "    elif design_type == \"latin_hypercube\":\n",
    "        design = lhs(*args)\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"Design type not recognized\")\n",
    "    return pd.DataFrame(design)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec20407",
   "metadata": {},
   "source": [
    "### Check the chosen Design\n",
    "\n",
    "* The plot visually demonstrates how the experiments are spread across the factor space, giving you an idea of the coverage and distribution of the experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf799f64",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "design_use = \"General Full Factorial\"\n",
    "\n",
    "levels = [3,3,3]\n",
    "factors = len(levels)\n",
    "\n",
    "# Name the variables\n",
    "Factor_1_ = \"%B initial\"\n",
    "Factor_2_ = \"slope %B\"\n",
    "Factor_3_ = \"Temperature\"\n",
    "\n",
    "design_table = create_design(design_use,levels)\n",
    "design_table.rename(columns={0:Factor_1_,1:Factor_2_,2:Factor_3_},inplace=True)\n",
    "\n",
    "# Create the 3D scatter plot\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.add_subplot(121, projection='3d')  # Changed to 121 to accommodate two plots side by side\n",
    "ax.scatter(design_table[Factor_1_], design_table[Factor_2_], design_table[Factor_3_])\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel(Factor_1_); ax.set_ylabel(Factor_2_); ax.set_zlabel(Factor_3_)\n",
    "ax.set_title(f\"{design_use} Design Points\")\n",
    "\n",
    "# Display the DataFrame next to the plot\n",
    "plt.subplot(122)  # Position for the table\n",
    "plt.axis('off')  # Turn off axis\n",
    "plt.table(cellText=design_table.values, colLabels=design_table.columns, cellLoc = 'center', loc='center')\n",
    "plt.show()\n",
    "\n",
    "# Alternatively, if you just want to display it as a DataFrame and not as a table in the plot\n",
    "#display(design_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8922c067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 3D scatter plot\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=design_table[Factor_1_], y=design_table[Factor_2_], z=design_table[Factor_3_], mode='markers',\n",
    "    marker=dict(size=5, opacity=0.8,),\n",
    "    text=[f'{Factor_1_}: {x}, {Factor_2_}: {y}, {Factor_3_}: {z}' for x, y, z in zip(design_table[Factor_1_], design_table[Factor_2_], design_table[Factor_3_])]\n",
    ")])\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title=f\"{design_use} Design Points\",\n",
    "    scene = dict(\n",
    "        xaxis_title=Factor_1_, # %B initial\n",
    "        yaxis_title=Factor_2_, # slope %B\n",
    "        zaxis_title=Factor_3_) # Temperature\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Save the figure as an HTML file in the 'images' subdirectory\n",
    "os.makedirs('images', exist_ok=True)\n",
    "fig.write_html('images/Model_start.html')\n",
    "\n",
    "#design_table.rename(columns={0:Factor_1, 1:Factor_2, 2:Factor_3}, inplace=True)\n",
    "#design_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f422b74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56acc458",
   "metadata": {},
   "source": [
    "#### Setting up your experimental table\n",
    "\n",
    "* Defining Factor Values\n",
    "\n",
    "* Create the Experimental table that will be used in the wet- laboratory\n",
    "\n",
    "    * The DataFrame is saved as a CSV file named \"Experimental Table from DoE - screening 3F 2L.csv\". The sep=\";\" specifies that the separator used in the file is a semicolon. index=False ensures that the DataFrame index is not included in the CSV file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d71e26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Factor_1 = [5, 15, 25]  # Values for Factor 1 - %B initial\n",
    "Factor_2 = [\"2.5%B/min\", \"5%B/min\", \"10%B/min\"]  # Values for Factor 2 - %B slope (%B/min.): (1)2.5%B/min. (2)5%B/min.; (3)10%B/min.\n",
    "#Factor_2 = [f\"2.5%B/min({(100-Factor_1[0]/100)/2.5:.01f} min.)\", f\"5%B/min({(100-Factor_1[1]/100)/5:.01f} min.)\", f\"10%B/min({(100-Factor_1[-1]/100)/10:.01f} min.)\"]  # Values for Factor 2 - %B slope (%B/min.): (1)2.5%B/min. (2)5%B/min.; (3)10%B/min.\n",
    "Factor_3 = [25, 42.5, 60]  # Values for Factor 3 - Temperature\n",
    "\n",
    "# Mapping for each factor\n",
    "mapping_factor_1 = {0: Factor_1[0], 1: Factor_1[1], 2: Factor_1[-1]}\n",
    "mapping_factor_2 = {0: Factor_2[0], 1: Factor_2[1], 2: Factor_2[-1]}\n",
    "mapping_factor_3 = {0: Factor_3[0], 1: Factor_3[1], 2: Factor_3[-1]}\n",
    "\n",
    "# Assuming 'design_table' is the DataFrame with -1, 0, and +1 (ex. box_behnken design)\n",
    "exp_table = design_table.copy()\n",
    "\n",
    "# Map the factors\n",
    "exp_table.iloc[:, 0] = exp_table.iloc[:, 0].map(mapping_factor_1)\n",
    "exp_table.iloc[:, 1] = exp_table.iloc[:, 1].map(mapping_factor_2)\n",
    "exp_table.iloc[:, 2] = exp_table.iloc[:, 2].map(mapping_factor_3)\n",
    "\n",
    "# Add experiment number and results columns\n",
    "exp_table[\"Experiment#\"] = exp_table.index +1\n",
    "exp_table['Number of Peaks'] = exp_table.apply(lambda _: '', axis=1) # Number of Peaks\n",
    "exp_table['Run Time'] = exp_table.apply(lambda _: '', axis=1) # Run Time\n",
    "exp_table['Results'] = exp_table.apply(lambda _: '', axis=1) # Run Time\n",
    "\n",
    "# Rename the columns to match the factors\n",
    "exp_table.rename(columns={exp_table.columns[0]: \"%B initial\", exp_table.columns[1]: \"%B slope\", exp_table.columns[2]: \"Temperature\"}, inplace=True)\n",
    "\n",
    "# Reorder columns for display\n",
    "exp_table = exp_table[['Experiment#', exp_table.columns[0], exp_table.columns[1], exp_table.columns[2], 'Results','Number of Peaks','Run Time']]\n",
    "\n",
    "# Save the experimental table to a CSV file\n",
    "exp_table.to_csv(f\"Experimental Table from DoE - {design_use}.csv\", sep=\";\", index=False)\n",
    "print(f\"Your experimental table ({design_use}) is ready as a CSV file for use.\")\n",
    "display(exp_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159f5e59",
   "metadata": {},
   "source": [
    "###### Create the pdf file with the Suggested Series of Methods for the Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e9cc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.lib import colors\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle\n",
    "from reportlab.lib.units import inch\n",
    "import pandas as pd\n",
    "\n",
    "# Create a PDF document\n",
    "pdf_file = f\"Suggested_Series_of_Methods_{design_use}.pdf\"\n",
    "document = SimpleDocTemplate(pdf_file, pagesize=A4)\n",
    "\n",
    "# Create a list to hold the elements to be added to the PDF\n",
    "elements = []\n",
    "\n",
    "# Title\n",
    "styles = getSampleStyleSheet()\n",
    "title_style = styles['Title']\n",
    "title = Paragraph(\"Suggested Series of Methods for the Experiment\", title_style)\n",
    "elements.append(title)\n",
    "\n",
    "# Add some space\n",
    "elements.append(Spacer(1, 12))\n",
    "\n",
    "# Add introductory text\n",
    "intro_text = Paragraph(f\"\"\"Below is the suggested series of methods to be used in the experiment,\n",
    "                           using the {design_use} design with {factors} factors and {levels} levels (for each factor)\n",
    "                           based on the design of experiments.\n",
    "                           \"\"\", styles['BodyText'])\n",
    "elements.append(intro_text)\n",
    "\n",
    "# Add some space\n",
    "elements.append(Spacer(1, 12))\n",
    "\n",
    "# Prepare the table data\n",
    "table_data = [exp_table.columns.tolist()] + exp_table.values.tolist()\n",
    "\n",
    "# Create a table with the data\n",
    "table = Table(table_data, hAlign='CENTER')\n",
    "\n",
    "# Style the table\n",
    "table.setStyle(TableStyle([\n",
    "    ('BACKGROUND', (0, 0), (-1, 0), colors.grey),\n",
    "    ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),\n",
    "    ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "    ('BOTTOMPADDING', (0, 0), (-1, 0), 12),\n",
    "    ('BACKGROUND', (0, 1), (-1, -1), colors.beige),\n",
    "    ('GRID', (0, 0), (-1, -1), 1, colors.black),\n",
    "]))\n",
    "\n",
    "# Add the table to the elements\n",
    "elements.append(table)\n",
    "\n",
    "# Add some space after the table\n",
    "elements.append(Spacer(1, 24))\n",
    "\n",
    "# Add a final comment1\n",
    "comment_text = Paragraph(\"OBS: (%B initial. - 100)/(%B slope) = time of gradient \")\n",
    "elements.append(comment_text)\n",
    "\n",
    "# Add a final comment2\n",
    "comment_text = Paragraph(f\"ex.: For when %B initial is 5 and %B slope is 2.5, the gradient will reach 100%B in {(100 - Factor_1[0]) / 2.5:.2f} min\", getSampleStyleSheet()['Normal'])\n",
    "elements.append(comment_text)\n",
    "\n",
    "# Add a final comment3\n",
    "comment_text = Paragraph(\"Produced by DOEpipeline. Please cite: 'available soon'\", styles['Italic'])\n",
    "elements.append(comment_text)\n",
    "\n",
    "# Build the PDF\n",
    "document.build(elements)\n",
    "\n",
    "print(f\"PDF {pdf_file} created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101547d2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a 3D scatter plot\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=exp_table[exp_table.columns[0]], y=exp_table[exp_table.columns[1]], z=exp_table[exp_table.columns[2]], mode='markers',\n",
    "    marker=dict(size=5, opacity=0.8,),\n",
    "    text=[f'{exp_table.columns[0]}: {x}, {exp_table.columns[1]}: {y}, {exp_table.columns[2]}: {z}' for x, y, z in zip(exp_table[exp_table.columns[0]], exp_table[exp_table.columns[1]], exp_table[exp_table.columns[2]])]\n",
    ")])\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title=f\"{exp_table} Design Points\",\n",
    "    scene = dict(\n",
    "        xaxis_title=exp_table.columns[0],\n",
    "        yaxis_title=exp_table.columns[1],\n",
    "        zaxis_title=exp_table.columns[2])\n",
    ")\n",
    "\n",
    "# Save the figure as an HTML file in the 'images' subdirectory\n",
    "os.makedirs('images', exist_ok=True)\n",
    "fig.write_html('images/Model.html')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca555b4",
   "metadata": {},
   "source": [
    "### Add columns that represent interaction between Factors and the results from the experiments\n",
    "\n",
    "* This adds a new column Results to design_table, containing the results from the experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf24d44",
   "metadata": {},
   "source": [
    "#### Read Chromatograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2bdb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = r'C:\\Users\\borge\\Downloads\\Cromatograma JULIANA\\DoE'\n",
    "os.chdir(directory_path)\n",
    "%pwd\n",
    "\n",
    "# Input/output directories and retention time range\n",
    "input_folder = directory_path\n",
    "output_folder = os.path.join(input_folder, 'data')\n",
    "retention_time_start = 1\n",
    "retention_time_end = 54\n",
    "\n",
    "# Run the process\n",
    "combined_df2 = dp.combine_and_trim_data(input_folder, output_folder, retention_time_start, retention_time_end)\n",
    "combined_df2\n",
    "\n",
    "import os\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Your existing code to create the Plotly figure\n",
    "fig = go.Figure()\n",
    "start_column = 1\n",
    "end_column = 53\n",
    "\n",
    "# Define a larger gap value to separate the traces more clearly\n",
    "gap = 200000  # Increased gap value for a more pronounced separation between traces\n",
    "\n",
    "# Ensure all columns being plotted are numeric\n",
    "for column in combined_df2.columns[start_column:end_column + 1]:\n",
    "    combined_df2[column] = pd.to_numeric(combined_df2[column], errors='coerce').fillna(0)\n",
    "\n",
    "# Iterate over the specified columns and add each trace with a vertical offset\n",
    "for i, column in enumerate(combined_df2.columns[start_column:end_column + 1]):\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=combined_df2['RT(min)'],\n",
    "        y=combined_df2[column] + i * gap,  # Offset each trace by 'i * gap'\n",
    "        mode='lines',\n",
    "        name=column\n",
    "    ))\n",
    "\n",
    "# Update the layout of the figure\n",
    "fig.update_layout(\n",
    "    title='Stacked Chromatograms with Larger Gaps',\n",
    "    xaxis_title='RT (min)',\n",
    "    yaxis_title='Intensity (Stacked)',\n",
    "    legend_title='Samples',\n",
    "    hovermode='closest',\n",
    "    width=1000,  # Set the width of the figure\n",
    "    height=1000  # Set the height of the figure\n",
    ")\n",
    "\n",
    "# Save the figure as an HTML file in the 'images' subdirectory\n",
    "os.makedirs('images', exist_ok=True)\n",
    "fig.write_html('images/stacked_chromatograms_larger_gap.html')\n",
    "\n",
    "# Show the figure (optional)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162c1f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Define a list of experiments to compare\n",
    "selected_experiments = [\n",
    "    \"DoE11\",  # Replace with actual column names for the samples/experiments\n",
    "    \"DoE14\",\n",
    "    \"DoE17\"\n",
    "]\n",
    "\n",
    "# Ensure the selected experiments exist in the DataFrame\n",
    "available_experiments = [col for col in selected_experiments if col in combined_df2.columns]\n",
    "\n",
    "# Create a Plotly figure\n",
    "fig = go.Figure()\n",
    "gap = 200000  # Set the gap for separating traces\n",
    "\n",
    "# Iterate over the selected experiments and plot\n",
    "for i, column in enumerate(available_experiments):\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=combined_df2['RT(min)'],  # Ensure RT(min) is the time column\n",
    "        y=combined_df2[column] + i * gap,  # Offset by i * gap\n",
    "        mode='lines',\n",
    "        name=column\n",
    "    ))\n",
    "\n",
    "# Update the layout\n",
    "fig.update_layout(\n",
    "    title='Selected Chromatograms Comparison',\n",
    "    xaxis_title='RT (min)',\n",
    "    yaxis_title='Intensity (Stacked)',\n",
    "    legend_title='Samples',\n",
    "    hovermode='closest',\n",
    "    width=1000,\n",
    "    height=1000\n",
    ")\n",
    "\n",
    "# Save the figure as an HTML file in the 'images' subdirectory\n",
    "os.makedirs('images', exist_ok=True)\n",
    "fig.write_html('images/selected_chromatograms_comparison.html')\n",
    "\n",
    "# Show the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251c1ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks, savgol_filter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Initialize a dictionary to store the number of peaks for each sample\n",
    "peaks_count = {}\n",
    "\n",
    "# Iterate over each sample column to detect peaks\n",
    "for column in combined_df2.columns[start_column:end_column + 1]:\n",
    "    # Extract the intensity values for the current sample\n",
    "    intensity_values = combined_df2[column].fillna(0).values  # Replace NaNs with 0\n",
    "    \n",
    "    # Apply baseline correction\n",
    "    baseline = savgol_filter(intensity_values, window_length=51, polyorder=3)\n",
    "    corrected_intensity = intensity_values - baseline\n",
    "\n",
    "    # Detect peaks in the corrected intensity values\n",
    "    peaks, properties = find_peaks(\n",
    "        corrected_intensity,\n",
    "        height=1000,  # Reduced height for smaller peaks\n",
    "        prominence=3000,  # Lower prominence to include less distinct peaks\n",
    "        distance=2,  # Allow closely spaced peaks\n",
    "        width=(2, None)  # Include broader peaks\n",
    "    )\n",
    "\n",
    "    # Count the number of detected peaks\n",
    "    peaks_count[column] = len(peaks)\n",
    "\n",
    "    # Create an interactive plot for one column\n",
    "    if column == combined_df2.columns[start_column+1]:  # Plot only for the first column as an example\n",
    "        fig = go.Figure()\n",
    "\n",
    "        # Add original intensity trace\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=combined_df2['RT(min)'],\n",
    "            y=intensity_values,\n",
    "            mode='lines',\n",
    "            name='Original Intensity'\n",
    "        ))\n",
    "\n",
    "        # Add corrected intensity trace\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=combined_df2['RT(min)'],\n",
    "            y=corrected_intensity,\n",
    "            mode='lines',\n",
    "            name='Corrected Intensity'\n",
    "        ))\n",
    "\n",
    "        # Add baseline trace\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=combined_df2['RT(min)'],\n",
    "            y=baseline,\n",
    "            mode='lines',\n",
    "            name='Baseline',\n",
    "            line=dict(dash='dash')\n",
    "        ))\n",
    "\n",
    "        # Add detected peaks\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=combined_df2['RT(min)'][peaks],\n",
    "            y=corrected_intensity[peaks],\n",
    "            mode='markers',\n",
    "            name='Peaks',\n",
    "            marker=dict(color='red', size=10)\n",
    "        ))\n",
    "\n",
    "        # Update layout for zoomable and interactive features\n",
    "        fig.update_layout(\n",
    "            title=f\"Interactive Peaks for {column}\",\n",
    "            xaxis_title=\"RT (min)\",\n",
    "            yaxis_title=\"Intensity\",\n",
    "            legend_title=\"Legend\",\n",
    "            hovermode=\"closest\"\n",
    "        )\n",
    "\n",
    "        # Show the plot\n",
    "        fig.show()\n",
    "\n",
    "# Convert the peaks count dictionary to a DataFrame for better visualization\n",
    "peaks_count_df = pd.DataFrame(list(peaks_count.items()), columns=['Sample', 'Number of Peaks'])\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "peaks_count_df.to_csv('images/peaks_count_with_slope.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219f5ba6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in combined_df2.columns[start_column:end_column + 1]:\n",
    "    dp.plot_interactive_peaks(combined_df2, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2092f614",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fcabe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "B0 = np.ones(len(design_table))\n",
    "design_table[\"B0\"] = B0\n",
    "\n",
    "# Create new columns by multiplying existing columns\n",
    "design_table['Factor_1_2'] = design_table[Factor_1_] * design_table[Factor_2_]\n",
    "design_table['Factor_1_1'] = design_table[Factor_1_] * design_table[Factor_1_]\n",
    "design_table['Factor_2_2'] = design_table[Factor_2_] * design_table[Factor_2_]\n",
    "\n",
    "# Load the Results into the Design Table\n",
    "#results = pd.read_csv(\"results.csv\")\n",
    "Number_of_peaks = peaks_count_df[\"Number of Peaks\"] #[28,24,23,29,28,25,20,24,24,27,22,22,26,24,22,30,27,27,25,26,23,26,27,23,29,27,29]\n",
    "\n",
    "Run_time = [38, 34, 30, 19, 17, 15, 9.5, 8.5, 7.5, 38, 34, 30, 19, 17, 15, 9.5, 8.5, 7.5, 38, 34, 30, 19, 17, 15, 9.5, 8.5, 7.5]\n",
    "\n",
    "#Run_time = [43,39,35,25,23,21,17,16,15,42,38,34,25,23,21,17,15,14,46,37,33,24,22,20,15,24,13]\n",
    "\n",
    "# Create a DataFrame from the provided lists\n",
    "data = {'Number_of_peaks': Number_of_peaks, 'Run_time': Run_time}\n",
    "\n",
    "# Calculate the Results as the division of Number_of_peaks by Run_time\n",
    "results = [(peaks*1.5) / (np.log(time))  for peaks, time in zip(Number_of_peaks, Run_time)]\n",
    "#results = [(peaks*2) / ((time))  for peaks, time in zip(Number_of_peaks, Run_time)]\n",
    "#results = Number_of_peaks\n",
    "\n",
    "# Create the design_table DataFrame\n",
    "#design_table = pd.DataFrame(data)\n",
    "design_table['Results'] = results\n",
    "\n",
    "#num_rows = len(design_table)\n",
    "#random_floats = np.random.random(num_rows)\n",
    "#results = pd.DataFrame({'Result': random_floats})\n",
    "\n",
    "design_table2 = design_table[['B0', Factor_1_,# %B initial\n",
    "                             Factor_2_,# slope %B\n",
    "                             Factor_3_,# Temperature\n",
    "                             'Factor_1_2', 'Factor_1_1','Factor_2_2', 'Results']]\n",
    "\n",
    "design_table2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4051e971",
   "metadata": {},
   "source": [
    "#### Effect\n",
    "A linear regression analysis to model how the independent variables (Factor_1, Factor_2, their interactions, and squared terms) affect the dependent variable (Results). \n",
    "* The calculated coefficients describe the relationship, and the standard errors provide insight into the reliability of these coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c7dbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "errorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0f34b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting y-values (dependent variable) and x-values (independent variables)\n",
    "y = design_table[['Results']].values\n",
    "X = design_table[[Factor_1_, Factor_2_, Factor_3_, \"Factor_1_2\", \"Factor_1_1\", \"Factor_2_2\"]].values\n",
    "\n",
    "# Add a column of ones to X to include an intercept in the model\n",
    "X = np.hstack([np.ones((X.shape[0], 1)), X])\n",
    "\n",
    "# Perform linear regression\n",
    "coefficients, residuals, rank, s = np.linalg.lstsq(X, y, rcond=None)\n",
    "\n",
    "# Calculate variance of residuals\n",
    "sigma_squared = residuals / (len(y) - X.shape[1])  # Adjusted for degrees of freedom\n",
    "\n",
    "# Define factor names\n",
    "factor_names = [\n",
    "    \"Intercept\",\n",
    "    Factor_1_,\n",
    "    Factor_2_,\n",
    "    Factor_3_,\n",
    "    \"Interaction (%B initial * slope %B)\",\n",
    "    \"Squared (%B initial)^2\",\n",
    "    \"Squared (slope %B)^2\"\n",
    "]\n",
    "\n",
    "# Residual variance (sigma^2)\n",
    "residual_variance = residuals / (len(y) - X.shape[1])\n",
    "\n",
    "# Covariance matrix of coefficients\n",
    "cov_matrix = residual_variance * np.linalg.inv(X.T @ X)\n",
    "\n",
    "# Standard errors for coefficients\n",
    "standard_errors = np.sqrt(np.diag(cov_matrix))\n",
    "\n",
    "# Organize coefficients and standard errors into a DataFrame\n",
    "coeff_df = pd.DataFrame({\n",
    "    \"Factor\": factor_names,\n",
    "    \"Coefficient\": coefficients.flatten(),\n",
    "    \"Standard Error\": standard_errors.flatten()\n",
    "})\n",
    "\n",
    "# Display the organized output\n",
    "display(coeff_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78f5e92",
   "metadata": {},
   "source": [
    "Interpretation of the Table:\n",
    "\n",
    "    Intercept:\n",
    "        The intercept (30.9330.93) represents the predicted response when all predictors are set to zero.\n",
    "        The standard error for the intercept is relatively small, indicating good confidence in its estimate.\n",
    "\n",
    "    Main Effects:\n",
    "        %B initial and slope %B have similar standard errors (1.37 and 1.37), suggesting similar confidence in their coefficients.\n",
    "        Temperature has a much smaller standard error (0.36 and 0.36), indicating higher precision for this factor's coefficient estimate.\n",
    "\n",
    "    Interaction and Quadratic Terms:\n",
    "        The interaction term and squared terms also have reasonable standard errors, reflecting the combined effects of predictors.\n",
    "        The standard error of 0.62 and 0.62 for the squared terms indicates moderate variability in these coefficients.\n",
    "        \n",
    "Magnitude of Effect\n",
    "\n",
    "    The absolute value of the coefficients indicates the strength of each factor’s effect on the response variable.\n",
    "    Larger coefficients (positive or negative) correspond to stronger effects.\n",
    "\n",
    "From the table:\n",
    "\n",
    "    %B initial: Coefficient = −2.18−2.18 (strong negative effect)\n",
    "    Temperature: Coefficient = 1.811.81 (strong positive effect)\n",
    "    Other coefficients are smaller in magnitude, indicating weaker interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee37b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Generate predictions based on the model coefficients\n",
    "y_pred = X @ coefficients\n",
    "\n",
    "# Calculate residuals\n",
    "residuals = y - y_pred\n",
    "\n",
    "# Calculate R-squared value\n",
    "r2 = r2_score(y, y_pred)\n",
    "\n",
    "# Plot residuals vs fitted values\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_pred, residuals, alpha=0.7, edgecolor='k')\n",
    "plt.axhline(y=0, color='r', linestyle='--', linewidth=1)\n",
    "plt.title(\"Residuals vs Fitted Values\")\n",
    "plt.xlabel(\"Fitted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Histogram of residuals\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(residuals, bins=15, color='skyblue', edgecolor='k', alpha=0.7)\n",
    "plt.title(\"Histogram of Residuals\")\n",
    "plt.xlabel(\"Residuals\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Display R-squared value\n",
    "r2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66bfc56",
   "metadata": {},
   "source": [
    "Observations:\n",
    "\n",
    "    Residuals vs. Fitted Values:\n",
    "        The residuals appear randomly scattered around the horizontal axis (y=0), which is a good indicator of no apparent pattern in the residuals.\n",
    "        This randomness suggests that the model fits the data reasonably well and that there are no obvious violations of linear regression assumptions (e.g., no strong heteroscedasticity or non-linearity).\n",
    "\n",
    "    Histogram of Residuals:\n",
    "        The residuals appear to be fairly symmetric around zero.\n",
    "        While it suggests approximate normality, this would need to be formally tested with a Shapiro-Wilk test or a Q-Q plot for further confirmation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680b124b",
   "metadata": {},
   "source": [
    "___\n",
    "### Creating the Response Surface matrix\n",
    "\n",
    "* Creating a Response Surface matrix involves setting up a framework where you can later input the responses (or outcomes) of your experiments based on varying levels of two factors. The code you've provided sets up such a matrix with values ranging from -1 to 1 (representing the factor levels) and divides this range into 11 steps.\n",
    "\n",
    "* When you run Resp_surf_ffact, it will display an 11x11 grid. Initially, all cells are filled with zeros. This matrix serves as a template where you can input the results of your experiments. Each cell corresponds to a combination of factor levels (one level from the horizontal axis and one from the vertical axis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689bf2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = np.linspace(-1, 1, 11)\n",
    "\n",
    "# Create an 11x11 DataFrame with zeros (or any default value)\n",
    "Resp_surf = pd.DataFrame(np.zeros((12, 12)))\n",
    "\n",
    "# Set the headers and index with the same vector values\n",
    "Resp_surf.columns = [''] + list(vector)\n",
    "Resp_surf.index = [''] + list(vector)\n",
    "Resp_surf = Resp_surf.iloc[1:]\n",
    "Resp_surf = Resp_surf.iloc[:, 1:]\n",
    "Resp_surf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431bc2b4",
   "metadata": {},
   "source": [
    "Ensure that the coefficients array is defined with the appropriate values. This array should contain six elements representing the constant term, the linear coefficients, the interaction coefficient, and the quadratic coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b46e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "Resp_surf_ffact2 = Resp_surf\n",
    "\n",
    "# Populate the DataFrame\n",
    "for i in range(11):  # Skip the first row and column\n",
    "    for j in range(11):\n",
    "        x = Resp_surf.columns[j]  # Corresponding vector value for the column\n",
    "        y = Resp_surf.index[i]    # Corresponding vector value for the row\n",
    "        # Apply the formula\n",
    "        Resp_surf.iloc[i, j] = (coefficients[0] + coefficients[1]*x + coefficients[2]*y +\n",
    "                                coefficients[3]*x*y + coefficients[4]*x*x + coefficients[5]*y*y)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "#display(Resp_surf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41245a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "Resp_surf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250d08c2",
   "metadata": {},
   "source": [
    "#### Creating a 3D surface plot from the data in your Response Surface matrix\n",
    "\n",
    "* This type of plot is particularly useful for visualizing the relationship between two factors and a response variable in a clear, intuitive manner.\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "* The plot visually represents how changes in 'Factor_1' and 'Factor_2' together affect the yield (response variable). Peaks and valleys in the surface indicate combinations of factor levels that result in high and low yields, respectively.\n",
    "\n",
    "Optimization:\n",
    "\n",
    "* This kind of plot can be used to identify optimal combinations of factor levels for maximizing or minimizing the response variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d19ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming Resp_surf2 is your DataFrame\n",
    "\n",
    "# Create coordinate arrays for the x and y values\n",
    "X, Y = np.meshgrid(Resp_surf_ffact2.columns.astype(float), Resp_surf_ffact2.index.astype(float))\n",
    "\n",
    "# Get the z values from the DataFrame and handle NaN or infinite values\n",
    "Z = Resp_surf_ffact2.values\n",
    "Z = np.nan_to_num(Z)  # Replace NaN with 0 and infinite with large finite numbers\n",
    "\n",
    "# Ensure all arrays are of numeric type\n",
    "X, Y, Z = [np.array(arr, dtype=float) for arr in [X, Y, Z]]\n",
    "\n",
    "# Create a 3D plot\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plot a surface\n",
    "surf = ax.plot_surface(X, Y, Z, cmap='viridis', edgecolor='none')\n",
    "\n",
    "# Add labels and title\n",
    "ax.set_xlabel(Factor_1_) #Factor_1\n",
    "ax.set_ylabel(Factor_2_) #Factor_2\n",
    "ax.set_zlabel('Yield') #Factor_3\n",
    "ax.set_title('3D Surface Plot')\n",
    "\n",
    "# Add a color bar\n",
    "fig.colorbar(surf)\n",
    "\n",
    "# Save the figure as an HTML file in the 'images' subdirectory\n",
    "os.makedirs('images', exist_ok=True)\n",
    "fig.savefig('images/3D_Surface_Plot.png') \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728611c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Assuming Resp_surf_ffact2 is your DataFrame containing the response surface data\n",
    "\n",
    "# Create coordinate arrays for %B initial and Temperature values\n",
    "# Adjust the vectors according to the specific layout of your data if needed\n",
    "X, Y = np.meshgrid(Resp_surf_ffact2.columns.astype(float), Resp_surf_ffact2.index.astype(float))\n",
    "\n",
    "# Get the z values from the DataFrame and handle NaN or infinite values\n",
    "Z = Resp_surf_ffact2.values\n",
    "Z = np.nan_to_num(Z)  # Replace NaN with 0 and infinite with large finite numbers\n",
    "\n",
    "# Ensure all arrays are of numeric type\n",
    "X, Y, Z = [np.array(arr, dtype=float) for arr in [X, Y, Z]]\n",
    "\n",
    "# Create a 3D plot\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plot a surface\n",
    "surf = ax.plot_surface(X, Y, Z, cmap='viridis', edgecolor='none')\n",
    "\n",
    "# Set the correct labels for the axes to reflect the interaction between %B initial and Temperature\n",
    "ax.set_xlabel(Factor_1_)  # Adjusted to reflect Factor_1\n",
    "ax.set_ylabel(Factor_3_)  # Adjusted to reflect Factor_3\n",
    "ax.set_zlabel('Yield')  # The response variable\n",
    "ax.set_title('3D Surface Plot of %B Initial vs Temperature Interaction')\n",
    "\n",
    "# Add a color bar for the surface plot\n",
    "fig.colorbar(surf, ax=ax, shrink=0.5, aspect=5)\n",
    "\n",
    "# Save the figure as an image file\n",
    "os.makedirs('images', exist_ok=True)\n",
    "fig.savefig('images/3D_Surface_Plot_Initial_Temperature.png')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fe5ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Assuming Resp_surf_ffact2 is your DataFrame containing the response surface data\n",
    "\n",
    "# Create coordinate arrays for %B slope and Temperature values\n",
    "# Adjust the vectors according to the columns and index of your data\n",
    "X, Y = np.meshgrid(Resp_surf_ffact2.columns.astype(float), Resp_surf_ffact2.index.astype(float))\n",
    "\n",
    "# Get the z values from the DataFrame and handle NaN or infinite values\n",
    "Z = Resp_surf_ffact2.values\n",
    "Z = np.nan_to_num(Z)  # Replace NaN with 0 and infinite with large finite numbers\n",
    "\n",
    "# Ensure all arrays are of numeric type\n",
    "X, Y, Z = [np.array(arr, dtype=float) for arr in [X, Y, Z]]\n",
    "\n",
    "# Create a 3D plot\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plot a surface\n",
    "surf = ax.plot_surface(X, Y, Z, cmap='viridis', edgecolor='none')\n",
    "\n",
    "# Set the correct labels for the axes to reflect the interaction between %B slope and Temperature\n",
    "ax.set_xlabel('%B slope')  # Adjusted to reflect Factor_2\n",
    "ax.set_ylabel('Temperature')  # Adjusted to reflect Factor_3\n",
    "ax.set_zlabel('Yield')  # The response variable\n",
    "ax.set_title('3D Surface Plot of %B Slope vs Temperature Interaction')\n",
    "\n",
    "# Add a color bar for the surface plot\n",
    "fig.colorbar(surf, ax=ax, shrink=0.5, aspect=5)\n",
    "\n",
    "# Save the figure as an image file\n",
    "os.makedirs('images', exist_ok=True)\n",
    "fig.savefig('images/3D_Surface_Plot_Slope_Temperature.png')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83778722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Create coordinate arrays for the x and y values\n",
    "X, Y = np.meshgrid(Resp_surf_ffact2.columns.astype(float), Resp_surf_ffact2.index.astype(float))\n",
    "\n",
    "# Get the z values from the DataFrame\n",
    "Z = Resp_surf_ffact2.values\n",
    "\n",
    "# Create a Plotly 3D surface plot\n",
    "fig = go.Figure(data=[go.Surface(z=Z, x=X, y=Y, contours_z=dict(\n",
    "    show=True, usecolormap=True, highlightcolor=\"limegreen\", project_z=True))])\n",
    "\n",
    "# Update the layout\n",
    "fig.update_layout(\n",
    "    title='3D Surface Plot with Projections',\n",
    "    scene=dict(\n",
    "        xaxis_title='%B initial', \n",
    "        yaxis_title='%B slope',\n",
    "        zaxis_title='Intensity',\n",
    "        aspectmode='manual',  # Adjust the aspect ratio manually\n",
    "        aspectratio=dict(x=1, y=1, z=0.5)  # Set aspect ratio to make it less slender\n",
    "    ),\n",
    "    autosize=True,\n",
    "    width=1000,\n",
    "    height=1000,\n",
    "    margin=dict(l=65, r=50, b=65, t=50)\n",
    ")\n",
    "\n",
    "# Save the figure as an HTML file in the 'images' subdirectory\n",
    "os.makedirs('images', exist_ok=True)\n",
    "fig.write_html('images/3D_Surface_Plot_interactive.html')\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a0a582",
   "metadata": {},
   "source": [
    "##### with Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53e6ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Assuming design_table includes all factors and interaction terms\n",
    "# Extracting y-values (dependent variable) and x-values (independent variables)\n",
    "y = design_table[['Results']].values\n",
    "\n",
    "# Update X to include Factor_3 and its interaction/squared terms\n",
    "X = design_table[[\"Factor_1\", \"Factor_2\", \"Factor_3\", \"Factor_1_2\", \"Factor_1_1\", \"Factor_2_2\"]].values\n",
    "\n",
    "# Add a column of ones to X to include an intercept in the model\n",
    "X = np.hstack([np.ones((X.shape[0], 1)), X])\n",
    "\n",
    "# Perform linear regression\n",
    "coefficients, residuals, rank, s = np.linalg.lstsq(X, y, rcond=None)\n",
    "\n",
    "# Display the coefficients\n",
    "print(\"Coefficients:\", coefficients.flatten())\n",
    "\n",
    "# Standard error calculation (optional for regression diagnostics)\n",
    "standard_error = np.sqrt(residuals / (len(y) - len(coefficients)))\n",
    "print(\"Standard Error:\", standard_error)\n",
    "\n",
    "# Generate mesh grid for three factors: %B initial, %B slope, and Temperature\n",
    "vector_1 = np.linspace(min(design_table['Factor_1']), max(design_table['Factor_1']), 11)\n",
    "vector_2 = np.linspace(min(design_table['Factor_2']), max(design_table['Factor_2']), 11)\n",
    "vector_3 = np.linspace(min(design_table['Factor_3']), max(design_table['Factor_3']), 11)\n",
    "\n",
    "# Create mesh grid for three factors\n",
    "X_grid, Y_grid, Z_grid = np.meshgrid(vector_1, vector_2, vector_3)\n",
    "\n",
    "# Calculate the response surface based on the regression coefficients\n",
    "Response = (coefficients[0] +\n",
    "            coefficients[1] * X_grid +\n",
    "            coefficients[2] * Y_grid +\n",
    "            coefficients[3] * Z_grid +\n",
    "            coefficients[4] * X_grid * Y_grid +\n",
    "            coefficients[5] * X_grid * X_grid +\n",
    "            coefficients[6] * Y_grid * Y_grid)\n",
    "\n",
    "# Create a 3D surface plot\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Flatten the arrays for plotting\n",
    "ax.plot_surface(X_grid[:, :, 0], Y_grid[:, :, 0], Response[:, :, 0], cmap='viridis', edgecolor='none')\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel('%B initial')  # Factor_1\n",
    "ax.set_ylabel('%B slope')    # Factor_2\n",
    "ax.set_zlabel('Response')    # Response with Temperature (Factor_3)\n",
    "ax.set_title('3D Surface Plot Including Temperature')\n",
    "\n",
    "# Add a color bar for reference\n",
    "fig.colorbar(ax.plot_surface(X_grid[:, :, 0], Y_grid[:, :, 0], Response[:, :, 0], cmap='viridis', edgecolor='none'))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6d63f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Assuming design_table includes all factors and interaction terms\n",
    "# Extracting y-values (dependent variable) and x-values (independent variables)\n",
    "y = design_table[['Results']].values\n",
    "\n",
    "# Update X to include Factor_3 (Temperature) and its interaction/squared terms\n",
    "X = design_table[[\"Factor_1\", \"Factor_2\", \"Factor_3\", \"Factor_1_2\", \"Factor_1_1\", \"Factor_2_2\"]].values\n",
    "\n",
    "# Add a column of ones to X to include an intercept in the model\n",
    "X = np.hstack([np.ones((X.shape[0], 1)), X])\n",
    "\n",
    "# Perform linear regression\n",
    "coefficients, residuals, rank, s = np.linalg.lstsq(X, y, rcond=None)\n",
    "\n",
    "# Display the coefficients\n",
    "print(\"Coefficients:\", coefficients.flatten())\n",
    "\n",
    "# Standard error calculation (optional for regression diagnostics)\n",
    "standard_error = np.sqrt(residuals / (len(y) - len(coefficients)))\n",
    "print(\"Standard Error:\", standard_error)\n",
    "\n",
    "# Generate mesh grid for Temperature and %B slope, keeping %B initial at specific levels\n",
    "vector_2 = np.linspace(min(design_table['Factor_2']), max(design_table['Factor_2']), 11)  # %B slope\n",
    "vector_3 = np.linspace(min(design_table['Factor_3']), max(design_table['Factor_3']), 11)  # Temperature\n",
    "\n",
    "# Select levels for %B initial\n",
    "initial_levels = [min(design_table['Factor_1']), np.mean(design_table['Factor_1']), max(design_table['Factor_1'])]\n",
    "\n",
    "# Create figure for multiple surface plots\n",
    "fig = plt.figure(figsize=(18, 6))\n",
    "\n",
    "# Loop through different levels of %B initial\n",
    "for i, level in enumerate(initial_levels):\n",
    "    # Create mesh grid for Temperature vs %B slope\n",
    "    X_grid, Y_grid = np.meshgrid(vector_2, vector_3)\n",
    "    \n",
    "    # Calculate the response surface based on the regression coefficients\n",
    "    Response = (coefficients[0] +\n",
    "                coefficients[1] * level +  # %B initial fixed at different levels\n",
    "                coefficients[2] * X_grid +  # %B slope\n",
    "                coefficients[3] * Y_grid +  # Temperature\n",
    "                coefficients[4] * level * X_grid +\n",
    "                coefficients[5] * level * level +\n",
    "                coefficients[6] * X_grid * X_grid)\n",
    "\n",
    "    # Create a subplot for each level of %B initial\n",
    "    ax = fig.add_subplot(1, 3, i + 1, projection='3d')\n",
    "    surf = ax.plot_surface(X_grid, Y_grid, Response, cmap='viridis', edgecolor='none')\n",
    "\n",
    "    # Set plot labels and title\n",
    "    ax.set_xlabel('%B Slope')\n",
    "    ax.set_ylabel('Temperature')\n",
    "    ax.set_zlabel('Response')\n",
    "    ax.set_title(f'%B initial = {level}')\n",
    "\n",
    "    # Add a color bar for the response surface\n",
    "    fig.colorbar(surf, ax=ax, shrink=0.5, aspect=5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea87140",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Sample coefficients for the regression model (replace with actual values)\n",
    "coefficients = [1, 0.5, 0.2, -0.3, 0.1, 0.05, -0.02]\n",
    "\n",
    "# Temperature levels to test (e.g., 25°C, 35°C, 45°C)\n",
    "temperature_levels = [25, 35, 45]\n",
    "\n",
    "# Vectors for %B Slope and another independent variable (can be adjusted)\n",
    "vector_2 = np.linspace(0, 10, 50)  # %B Slope\n",
    "vector_3 = np.linspace(0, 10, 50)  # Another independent variable\n",
    "\n",
    "# Create a figure for 3D plots\n",
    "fig = plt.figure(figsize=(18, 6))\n",
    "\n",
    "# Loop through different levels of Temperature\n",
    "for i, temp in enumerate(temperature_levels):\n",
    "    # Create mesh grid for %B Slope vs another independent variable\n",
    "    X_grid, Y_grid = np.meshgrid(vector_2, vector_3)\n",
    "    \n",
    "    # Calculate the response surface based on the regression coefficients\n",
    "    Response = (coefficients[0] +\n",
    "                coefficients[1] * X_grid +  # %B Slope\n",
    "                coefficients[2] * Y_grid +  # Another independent variable\n",
    "                coefficients[3] * temp +    # Temperature fixed at different levels\n",
    "                coefficients[4] * X_grid * Y_grid +\n",
    "                coefficients[5] * temp * temp +\n",
    "                coefficients[6] * X_grid * X_grid)\n",
    "\n",
    "    # Create a subplot for each level of Temperature\n",
    "    ax = fig.add_subplot(1, 3, i + 1, projection='3d')\n",
    "    surf = ax.plot_surface(X_grid, Y_grid, Response, cmap='viridis', edgecolor='none')\n",
    "\n",
    "    # Set plot labels and title\n",
    "    ax.set_xlabel('%B Slope')\n",
    "    ax.set_ylabel('Another Variable')\n",
    "    ax.set_zlabel('Response')\n",
    "    ax.set_title(f'Temperature = {temp}°C')\n",
    "\n",
    "    # Add a color bar for the response surface\n",
    "    fig.colorbar(surf, ax=ax, shrink=0.5, aspect=5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef19e8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
